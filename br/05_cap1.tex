\chapter{Hist\'orico e Definiç\~ao} \label{1}

Segundo Paul Ceruzzi, há duas correntes históricas que se construíram nos arredores do objeto Software (CERUZZI, 1998). A primeira dessas correntes evita uma descrição demasiamente técnica por ser destinada a um publico amplo, interessa-se à formação das companhias privadas individuais (IBM, Apple, Microsoft). A segunda historiografia, por sua vez, foca-se sobre o nascimento das linguagens de programação (FORTRAN, COBOL, entre outros), questionando como cada linguagem apareceu e permitiu aos seus desenvolvedores de extrair novas funcionalidades do hardware.

Desde o trabalho de Ceruzzi, uma terceira corrente de historiografia foi se construindo paulatinamente nos arredores da observação do movimento do software livre e de código aberto durante os anos 80 e 90. Essa nova narrativa do movimento tecnológico computacional relatou as tradições da cultura hacker de programação. De suas origens nos laboratórios acadêmicos de informática dos anos 50 e 60, construiu-se a historia de como fatores econômicos e ideológicos formaram as tradições culturais e autorais da programação, e como essas recentes tradições afetaram e, até, determinaram que tipo de software esta sendo escrito.

Ademais, este capítulo introdutivo tem como propósito usar livremente essas três correntes de historiografia da computação para apresentar o movimento do software livre no seu contexto histórico, social e econômico. Num primeiro ponto, mostraremos como o conceito de software se formou como abstração do hardware e descreveremos os elementos concretos que recobrem, hoje, essas duas noções (\ref{1.1}). Depois, mostraremos como o objeto software constitui-se em grande escala ao acompanhar a historia do computador pessoal e das companhias que o construíram. Assim, observam-se os primeiros rastos da cultura \emph{open-source}, como reação à privatização do código (\ref{1.2}).  Ainda, na terceira parte, mostraremos a constituição das comunidades e licenças que formam o movimento do software livre, como as instituições que o promovem. Assim, através dos conflitos de interpretação do que é ser “livre” ou “aberto” para uma tecnologia, observa-se a heterogeneidade do movimento que chama a postular de uma definição sistemática (\ref{1.3}). Enfim, no quarto e ultimo ponto, relataremos alguns desafios contemporâneos que são em debates dentro das comunidades para ilustrar os sucessos e carências presentes no movimento (\ref{1.4}).

\section{Computador, hardware e software} \label{1.1}

\subsection{A abstração do Software} \label{1.1.1}

A origem da palavra “computador” designa um homem realizando operações matemáticas com a ajuda de ferramentas mecânicas. Dentre as ferramentas que ficaram, as mais conhecidas são: o ábaco (2700-2300 a.C.), o mecanismo antikythera (150-100 a.C.) e, datando do Renascimento, a regra de cálculo e o astrolábio. Os primeiros rastros de programabilidade, ou melhor, de automação das operações de cálculos, datam também da antiguidade, com o teatro mecânico de Heron d’Alexandria (10-70 d.C.) encenando uma peça de 10 minutos, com a ajuda de objetos animados por um sistema de cordas e alavancas cuja execução estava decidida com antecedência.  Associando essas primeiras ferramentas de automação do cálculo com a noção de programabilidade que podemos constituir a origem do sentido dado ao computador moderno. Assim, podemos falar do computador como uma máquina que trata dados (cálculos) a partir de instruções dadas (programabilidade). Em francês, o termo "computador" traduzia-se inicialmente por "calculador" (\emph{calculateur}). Foi um professor de latim da Sorbonne, Jacques Perret quem, mandado pela IBM, batizou o objeto de \emph{ordinateur} em refer\^encia à figura do ordenador na crença católica.

Entretanto, Foi somente entre 1940 e 1945 que surgiram os primeiros computadores semelhantes aos que são conhecidos atualmente. Tratavam-se de grandes máquinas ocupando quartos inteiros, consumindo a energia de centenas de micro-computadores semelhantes aos atuais. A revolução computacional dos anos 40 é o resultado da fusão entre vários esforços de exploração teóricos e práticos (BLACK, 2002). Baseando-se sobre a \emph{tradição matemática} constituídas pelas obras de Leibniz, Boole, entre outros, Alan Turing conseguiu expor as bases da computação de propósito geral nos anos 30, com a "Maquina Universal Turing". Isto é, uma representação abstrata e teórica de um dispositivo computacional. Segundo os comentários do próprio autor, “é possível inventar uma maquina única que poderia ser utilizada para computar qualquer seqüência”\footnote{“it is possible to invent a single machine which can be used to compute any computable sequence”} (TURING, 1936, p.241).

Contudo, a inspiração abstrata de Turing realizou-se concretamente pelo meio de uma tradição distinta: a \emph{tradição de engenharia}. Esse conjunto de escolas práticas permitiu, nos anos 40, que fossem construídas as primeiras maquinas eletrônicas de cálculos. Os primeiros dispositivos eletrônicos incorporando o sistema teórico de Turing foram o resultado da culminação das heranças empíricas de autores como John Napier (1550-1617), Blaise Pascal (1623-1666), Charles Babbage (1791-1871), entre outros.

Frente a essas maquinas, apareceu a necessidade de controlá-las, de produzir instruções que poderiam ser prescritas. Assim, como conseqüência dessa necessidade, nasceu o terceiro elemento que constituiu a computação moderna: \emph{a tradição de programação computacional}. Isso aconteceu notavelmente no âmbito do esforço cientifico realizado durante a segunda guerra mundial, por exemplo, por volta da maquina ENIAC, desenvolvida pela Universidade de Pensilvânia.

Servindo os propósitos de guerra, as primeiras máquinas computacionais dedicavam-se à velocidade de calculo, e por isso, estavam construídas com propósitos particulares e isolados, de tal forma que se entendia as noções, hoje estabelecidas, de hardware e software, num objeto só, como fundamentalmente dependente, uma da outra. Contudo, a idéia de “propósito geral” que se encontra no sistema de Turing, designa por tanto uma plataforma compatível com qualquer conjunto de instruções, como um dispositivo genérico capaz de realizar cálculos variados e adaptáveis. Em outros termos, embora as raízes teóricas da computação tivessem diferenciado hardware e software, as primeiras realizações práticas criaram maquinas que não permitiam a esses dois objetos de evoluir independentemente. Essas limitações apareceram com nitidez ao estender o uso dessas primeiras maquinas no mundo corporativo. Segundo as palavras de Maurice Black: “A chave para construir um computador usável – e conseqüentemente profitável – não é o fato de concebê-lo para desempenhar funções ou cálculos específicos, mas o de construir um hardware de propósito geral que poderia ser programado facilmente para qualquer propósito.”\footnote{“the key of making computer usable – and therefore profitable – lay not in designing them to perform specific functions or calculations, but in bulding general-purpose hardware that could easily be programmed to perform any task.”} (BLACK, 2002, p.40). Porém, como nota o historiador da computação Micheal Mahoney sobre esse período: 

\begin{quote}
Nos temos praticamente nenhum relatório histórico de como, começando nos anos 1950, governos, negócios, e indústrias, colocaram as suas operações no computador. Fora alguns estudos com um foco sociológico sobre os anos 70, a programação como nova atividade técnica, e os programadores como nova força de trabalho, não receberam atenção histórica.\footnote{“we have pratically no historical accounts of how, starting in the early 1950's, government, business, and industry put their operations on the computer. Aside from a few studies with a primarily sociological focus in the 1970's, programming as a new technical activity and programmers as a new labor force have received no historical attention.”}
\begin{flushright}
MAHONEY, 2002, p.92.
\end{flushright}
\end{quote}


Contudo, embora seja difícil dar atenção aos esforços isolados que permitiram a abstração progressiva do software como um objeto próprio, sujeito a evoluções independente da sua plataforma de execução, podemos sublinhar aqui um dos fatos importante da historia da computação, que permitiu que emergisse o conceito moderno de software. No âmbito das problemáticas procurando construir um hardware de propósito geral, o matemático John Von Neumann descreveu (VON NEUMANN, 1945) uma arquitetura cuja pretensão era de ser inteiramente digital, isto é, que as instruções sejam armanezadas na memória do computador – e não como circuito mecânico específico. Assim as instruções podiam ser transportadas de um computador ao outro. Esta idéia de "programa armanezado" mudou a face da computação e diferenciou o objeto software, do hardware.

Por um lado, isso permitiu às instruções serem desenvolvidas abstratamente, sem laço físico com o material da maquina, e por isso abriu as possibilidades de um desenvolvimento tecnológico colaborativo. Por outro lado, isto foi a origem do fenômeno de \emph{blackboxing} (caixa preta) dos programas, permitindo a seus desenvolvedores de entregar um produto finito cujo código fonte podia ser escondido. Assim, por essas duas razoes principais, Black pôde afirmar que “a abstração do software do hardware é o aspecto o mais importante do inicio da historia da programação” (BLACK, 2002, p.49).

Portanto, o conceito de software levou tempo a ser usado pelos atuantes das tecnologias informáticas. Segundo Matthew Fuller, o primeiro uso da palavra que foi publicado acha-se num artigo da revista \emph{American Mathematical Monthy} de 1958 (TUKEY, 1958, citado em FULLER, 2008). Tratava-se então da idéia que todos os problemas matemáticos podiam ser resolvidos por dentro das matemáticas, idéia que se encontra hoje mais por volta do conceito de algoritmo, entendido como abstração livre dos detalhes de implementação. Porém, é em 1968, quando IBM decidiu de dividir sua secção informática em dois departamentos, hardware e software, para escapar de um processo de Antitrust da administração americana, que o termo "software" levou boa parte de seu sentido comum. Contudo, será com a propagação dos computadores pessoais e a democratização do acesso às tecnologias computacionais, que o objeto "software" aparecera com toda sua dimensão social e política.

\subsection{Elementos principais do hardware e software} \label{1.1.2}

Embora sua estrutura tenha evoluído com o tempo, o computador é geralmente composto dos mesmos tipos de elementos: uma unidade de controle central que gere os diferentes componentes, uma unidade aritmética e lógica que realiza as operações e uma unidade de memória na qual os dados são armazenados e lidos. O computador com um todo recebe entradas (\emph{input}) e restitua saídas (\emph{output}). Essa dupla \emph{input}/\emph{output} pode ser reproduzida a todos os níveis da hierarquia que compõe um computador: entrada e saída para um programa, um componente, um circuito, etc. O conjunto de elementos físicos de um computador constitui seu hardware. A sua fabricação foi modificada em função de objetivos de rentabilidade, técnicos, espaciais que transformaram suas raízes mecânicas (transistores, tubos, entre outros) em circuitos miniaturas integrados. Vale mencionar que, as últimas pesquisas teóricas a respeito de hardware apontam tecnologias quânticas, químicas e ópticas que indicam desempenhos sem medida com as tecnologias atuais das mais avançadas.

Esse conjunto material gera dados, programas, protocolos, ou seja, um conjunto imaterial designado pelo termo genérico de software. Todos os softwares são criados com uma ou várias linguagens de programação. Trata-se de linguagens exclusivamente escritas, construídas para serem precisas e concisas, evitando assim possíveis ambigüidades. Uma vez que é interpretado pelo hardware (compilado), o software somente aparece como uma sucessão de bytes (zero e um), um fluxo binário incompreensível pelo ser humano (Figura \ref{fig1.1}). Embora os softwares possam designar um número ilimitado de objetos, podem ser classificados em vários tipos, vejamos:

\begin{itemize}
\item O \emph{Sistema Operacional} (SO), como por exemplo, Windows, Unix ou DOS. Ele organiza e coordena a atividade e a distribuição dos recursos finitos do hardware.
\item As \emph{bibliotecas}. Um conjunto de "sub-rotinas" chamadas para desenvolver programas maiores.

\item Os \emph {dados}. Trata-se tanto de protocolos de transferência (SMTP, FTP) como dos formatos de arquivos (JPEG, HTML, MPEG, XML).

\item Os \emph{aplicativos}. Podem ser ferramentas para escritórios (MS Office, OpenOffice.org), internet (browser, servidores web), gráficos (editor de imagens, criação 3D), áudio (Composição musical, mixagem), engenharia do software (compilador, debugger), jogos interativos, entre outros.
\end{itemize}


\begin{center}
\begin{figure}[htb]

\caption{C\'odigo fonte e formato binario}
\label{fig1.1}

\begin{multicols}{2}

\begin{verbatim}
$ echo “Hello World”
\end{verbatim}

\columnbreak

\begin{verbatim}
0110010101100011011010000
1101111001000000010001001
0010000110010101101100011
0110001101111001000000101
0111011011110111001001101
1000110010000100010
\end{verbatim}

\end{multicols}
\end{figure}
\end{center}


\section{P.C. e Software} \label{1.2}

\subsection{O P.C. e a informática de massa} \label{1.2.1}
	
Os computadores custavam tão caros para serem comprados, usados e mantidos que somente algumas universidades, empresas e órgãos governamentais os possuíam. Graças às evoluções tecnológicas que reduziram custos de produção, o espaço e a energia utilizadas por cada unidade, surgiram nos anos 70 os primeiros micro-computadores, ou computadores pessoais (\emph{Personnal Computer}, PC), que o termo "computador" vem designar hoje por padrão. Designando unicamente computadores de escritório (\emph{Desktop}), recentemente esse termo designa também os computadores portáveis (laptop, notebook) e os dispositivos reduzidos (mini-notebook, PDA, etc). Estes são geralmente utilizados por uma pessoa sozinha, o que os diferenciam dos servidores.

Com conseqüência disso, há um ambiente específico nos arredores dessas inovações tecnológicas. No período de revolução cultural americana dos anos 70, os campi universitários (particularmente o da Universidade de Stanford, na Califórnia) eram os lugares de encontro dos grandes nomes da produção de PCs, dentro dos quais se encontra Steve Jobs e Steve Wozniac (co-fundadores de Apple), Bill Gates e Paul Allen (Microsoft), Paul Graham, Bill Joy e outros. Eles conviveram com diversos movimentos sociais: marxistas, contra a guerra no Vietnam, zen-budista, ecologista, rock, ficção científica, entre outros (BRETON, 1990). Se esses movimentos sociais são relativamente ignorados por esses recentes atuantes das novas tecnologias, eles ficaram influenciados por um ambiente de hyper-diversidade alternativa, de transgressão e de inovação que formará as bases do que tornar-se-ia “os piratas do Vale do Silício”\footnote{Título do filme de Martin Burke (1999) inspirado pelo livro: FREIBERG, Paul e SWAINE, Micheal, \emph{Fire In The Valley}, 2000.}.

De acordo com Paul Graham, engenheiro da computação e contemporâneo dessa época, testemunha no seu ensaio \emph{The Power of a Marginal}: “O mundo ainda não tinha consciência que o fato de iniciar uma companhia de computadores era da mesma ordem do que ser artista ou pintor” (GRAHAM, 2006). Assim, Aceitando a idéia que as coisas novas e brilhantes são inspiradas e crescem às margens de uma sociedade, foi a coexistência aberta de muitas margens culturais num mesmo tempo e espaço que permitiu um ambiente de liberdade e audácia científica auspicioso às revoluções tecnológicas.

Os criadores dos computadores pessoais não imaginavam o sucesso que teria seu modelo tecnológico (NEGROPONTE, 1996). Eles aproveitaram dessa situação usando inovações a custos reduzidos. Por exemplo, a companhia Xerox que inventou a interface gráfica e o mouse, partilhou suas inovações com Apple, sem receber verba nenhuma. Os chefes da Xerox não acreditavam na utilidade dessas ferramentas e permitiram à Apple ver, informalmente, mas em detalhe, como funcionavam. Contudo, essas invenções contribuíram bastante ao sucesso do \emph{Apple II} em 1977 e o do PC de maneira geral.

Finalizando, as primeiras produções de computadores pessoais foram realizadas por grupos reduzidos em condições precárias, o que não impediu alguns de transformar suas estruturas e acompanhar o alargamento do mercado de consumidores, como é o caso para Apple e Microsoft. Porém os grandes grupos, como IBM ou HP, não demoraram a entrar no mercado e propor produtos equivalentes. Além de se estender a um público de engenheiros, o PC apareceu como um meio de trazer uma melhor qualidade de trabalho (TOFFLER, 1985), e foi nos escritórios que o PC foi bem aceito em grande escala, mais rapidamente. O modelo de estação de trabalho (\emph{Workstation}), considerado como uma plataforma de alta produtividade, substituiu paulatinamente as ferramentas do escritório tradicional.

\subsection{O desenvolvimento dos Softwares e o início da cultura open-source} \label{1.2.2}

O software e o conjunto de aplicativos que compõem um sistema não são o foco principal da indústria da informática. Exceto a Microsoft, nenhum atuante desenvolve um sistema operacional com pretensão universal, ou seja, aspirando a funcionar em cima de qualquer hardware. Como confiou o P.D.G. da Apple a respeito de Bill Gates, durante uma entrevista no show \emph{All Things Digital}: “Ele criou a primeira companhia de software antes que alguém nessa indústria saiba o que é uma companhia de software”\footnote{\emph{All Things Digital}, 30 de maio 2007.}. De fato, nessa época a indústria de informática se preocupava principalmente em vender e manter o material. Os softwares eram considerados acessórios porque a maioria dos utilizadores os desenvolviam por conta própria. Foi a aparição de um sistema com tempo partilhado (\emph{multitask}) que impôs a forma dos softwares que conhecemos hoje, tornado possível pela comercialização de disco rígido e de banda magnética permitindo armazenar, modificar e reutilizar programas (MÜLLER, 2001).

Uma informação importante é que numerosos sistemas compartilhados que rodavam nos computadores centrais de grandes instituições utilizavam a tecnologia Unix. Esta tecnologia foi desenvolvida por Ken Thompson e Dennis Ritchie dentro dos laboratórios da AT\&T (Bell), a primeira versão desse sistema operacional aparece em 1969. Entretanto, por causa de uma ação anterior na justiça (1949-1956) por abuso de posição dominante, e para evitar qualquer infração ao julgamento, Unix não foi comercializado. O programa foi colocado sob licença que as instituições conseguiriam comprar. O software sendo distribuído sem serviço pós-venda nem correção de bug, constituiu-se um esforço ativo de desenvolvimento nas universidades. A rede \emph{Usenet} tornou-se uma plataforma de troca de informações e de suporte para a utilização de Unix, e as inovações e correções de bugs circulam rapidamente. Além de ter um papel de coordenador, a Universidade de Stanford (Berkeley, CA-EUA) começou a desenvolver sua própria versão de Unix – BSD (\emph{Berkeley Software Distribution}) – publicada pela primeira vez em 1978 por Bill Joy. Quatro anos depois, em 1982, outras versões de Unix foram publicadas de forma comercial por IBM, HP, DEC, para executarem-se no hardware existente. Na mesma data Bill Joy saiu da Universidade de Berkeley e fundou a SUN cujas máquinas usaram BSD 4.2. Em 1984, AT\&T conseguiu, após uma nova ação em justiça, entrar no mercado da informática como um ator próprio e publica pela primeira vez uma versão comercial de Unix cujo código fonte ficara fechado dai em diante (MÜLLER, 2001).

Com isso, entendemos que Unix é a primeira proposta suficientemente realizada que permitiu pensar-se em um sistema universal. Com um código acessível, desde sua origem, aproveitou aperfeiçoamentos, modificações e adaptações que permitiram uma apropriação estendida, variada e criativa. Além disso, a influência desse sistema operacional ultrapassou os construtores de servidores. De fato, o ancestral da Internet, Arpanet, foi organizado e instalado a partir de sistemas Unix. Essa Tecnologia, embora esteja proprietária, foi apropriada por toda uma geração de engenheiros numa dinâmica de troca, de divisão e de aperfeiçoamentos constantes. É provavelmente aqui que se acham as raízes da filosofia \emph{open-source}, no meio do ardor das revoluções culturais e tecnológicas dos anos 70 nos Estados-Unidos. Parece que a interdição para AT\&T comercializar seu produto, permitiu que um novo modelo de desenvolvimento emergisse no mundo do software, deixando um espaço vazio no processo de radicalização proprietária da indústria da informática e particularmente do mercado imenso que abrir-se-ia com o computador pessoal. 


\section{Software Livre e de Código Aberto (SL/CA): comunidades, licenças e instituições} \label{1.3}

\subsection{Inventar e proteger um software livre} \label{1.3.1}

Foi uma pequena falha no sistema de proteção do produto Unix que permitiu em um curto prazo, que ele fosse apropriado, desenvolvido e aperfeiçoado por um conjunto de atuantes de diversos locais. Dessa curta fase ficou uma tradição de troca "aberta" de informações e, embora já estivesse presente no meio da informática, tratava-se, para seus adeptos, de protegê-la para que seus benefícios não sejam apropriados. A aposta foi rapidamente entendida e desde a primeira versão de Unix desenvolvida pela Universidade de Berkeley, uma licença foi criada. A licença BSD obriga os desenvolvedores e usuários a mencionar os nomes dos autores do dito programa. Ela exclui toda responsabilidade dos programadores em caso de disfunção e o código é aberto, mas pode ser fechado, por exemplo, para uma utilização comercial.

Além disso, A \emph{Free Software Fondation} (FSF – Fundação para o Software Livre), fundada em 1984 por Richard M. Stallman, vai articular, em termos ideológicos, e políticos os desafios de um software para ele ser chamado de "livre". A idéia é que cada linha de código é uma parcela de informação que, sendo traçada, partilhada e discutida, adaptar-se-ia melhor. Podemos observar que as metáforas não faltam ao discurso da fundação, as receitas de cozinha, por exemplo: descobrindo-se que batendo ovos e jogando-os numa estufa se faz uma omelete; porque deveríamos limitar nossa liberdade de partilhar essa dica com nosso vizinho, e nossa curiosidade de desenvolver outras receitas derivadas? Com essa pergunta simples, Stallman não defende um software de graça, como pode ser entendido na palavra inglês \emph{free} (“\emph{free as free beer}”), mas um modelo livre de desenvolvimento (“\emph{free as free society}”). Por isso, se chama livre e não gratuito em português. Também, é por isso que a apelação a mais utilizada pelas instituições internacionais, adicionam à sigla inglesa, o termo \emph{libre} da língua francesa e espanhola: \emph{Free/Libre and Open-Source Software} (F/LOSS).

Seguindo esse propósito, foi criado a Licença Pública Geral (GPL – \emph{General Public License}) que inspirou o movimento do software livre. Um código sob licença GPL é aberto e modificável, e deve ficar desse jeito. Nenhuma restrição às condições de base pode ser adicionada, e em complemento ao seu interesse jurídico, a GPL veicula uma ideologia simbolizada pelas “quatros liberdades”\footnote{Referência às four freedom proclamadas pelo Presidente dos EUA, Franklin D. Roosvelt durante o tradicional Discurso Anual ao Congresso do dia 06/01/1941.}: a liberdade de executar o programa, para qualquer propósito; a liberdade de estudar como o programa funciona e de puder adaptá-lo a suas necessidades; a liberdade de redistribuí-lo; a liberdade de melhorá-lo e partilhar com a comunidade.

Protegida por essa licença, a FSF iniciou um projeto ambicioso, aspirando oferecer um sistema operacional e aplicativos com bom desempenho e inteiramente livres. Então, no quadro do projeto GNU (acrônimo de \emph{GNU is not Unix}), centenas de programadores das regiões desenvolvidas do mundo acabaram desenvolvendo aplicativos semelhantes aos oferecidos pelo sistema Unix. Vários aplicativos criados nessa época ficaram até hoje conhecidos por ter bom desempenho (notavelmente GCC). Apesar de vários anos de trabalho, ainda não estava disponível um núcleo (\emph{kernel}) que permita o funcionamento de todos os aplicativos em um sistema único. Em 1991, Linus Torvalds, programador finlandês, publicou o código de seu \emph{kernel} “Linux” que juntava as realizações até então feitas, num sistema só, independente do \emph{kernel} proprietário da AT\&T. Desse jeito, completava-se os primeiros objetivos do projeto GNU e realizava-se o primeiro sistema operacional universal sob licença GPL: GNU/Linux. 

\subsection{Software Livre \emph{e/ou} de Código Aberto} \label{1.3.2}

Enquanto o movimento do Software Livre evoluiu num ambiente ainda pouco conhecido para a época, reivindicações cresceram internamente que apontavam a necessidade de abrir-se a patrocínios de instituições privadas. De fato, varias comunidades reclamaram que o sucesso do Linux não era ligado a sua característica de "livre" mas às suas vantagens e estabilidade oferecidas pelo acesso livre ao código fonte e seu modelo de desenvolvimento colaborativo. O ano de 1998 ocorreu uma cisão institucional para o movimento do software livre. Depois de 7 anos de vida, o sistema Linux não era mais marginal e começava a aparecer como uma alternativa credível para as empresas. Além da junção da Intel a \emph{Linux International}, a IBM, por sua vez, construiu um hardware para rodar especificamente com o Linux,  a empresa Netscape públicou o código fonte de seu navegador no site Mozilla.org. Ademais, os códigos de StarOffice (predecessor de OpenOffice) e de Solaris (Sistema Operacional da Sun) foram publicados. Muitas vozes se juntam por volta de eventos como a publicação do ensaio de Eric Raymond, \emph{The Cathedral and the Bazaar} (RAYMOND, 1997), e o \emph{Open-Source Summit}, realizado pelas edições \emph{O’Reilly \& Associates}. A idéia desenvolvida nesses eventos é de afastar as pretensões ideológicas da FSF e a defesa de um direito humano a co-criar/modificar a produção de um código e assim privilegiar a potencia e a rentabilidade de um modo de desenvolvimento. Foi no âmbito dessas idéias que se construiu o movimento \emph{open-source} (de código aberto) por parte das instituições privadas (IBM, Intel, O’Reilly, SUN, RedHat, etc.) e de uma filosofia pragmática dos princípios que fizeram o movimento do software livre.

Essa denominação de \emph{open-source} insiste sobre o código aberto e coloca de lado os compromissos políticos e ideológicos que ficarão, daqui por diante, reivindicações quase-exclusivas da FSF. Agrupam-se geralmente com o nome genérico de \emph{Free/Libre and Open Source Software} (FOSS, F/LOSS) e em português: Software Livre e de Código Aberto (SL/CA). Para seus atores, os nomes de “movimento \emph{open-source}” ou de “movimento do software livre” convocam realidades e ambições bem diferentes que recusam ser assimiladas umas – ideológicas – com as outras – pragmáticas. Porém, se os defensores do \emph{open-source} fazem livremente referência aos ícones da asa livre do movimento, o inverso não é bem-vindo e, a simples pronunciação de "\emph{open-source}" nos canais IRC do projeto GNU ganha um “não se faz open-source aqui!”.

\begin{figure}[htb]

\caption{Apelações do movimento do software livre.} \label{fig1.2}

\begin{center}
SL/CA, FOSS, F/LOSS\\

\begin{tabular}{|c1|p{8cm}|}
\hline
Asa ideológico-política & Asa pragmática \\
\hline

\emph{Free Software}, Software Livre & Software de Código Aberto \\

 & \emph{Open-Source Software (OSS)} \\

Exemplo de comunidades: & Exemplo de comunidades: \\

GNU & BSD, Mozilla \\
\hline

\end{tabular}
\end{center}
\end{figure}


\subsection{Licenças e instituições} \label{1.3.3}

Desde o início do movimento FOSS, e mais ainda desde a cisão explícita de 1998, multiplicaram-se as licenças para proteger o trabalho das comunidades. Espalharam-se muitas licenças, cuja semelhança é a proteção numa certa medida da acessibilidade ao código fonte, porém se diferenciam pelas restrições que trazem às quatro liberdades fundamentais do movimento do livre. Se alguns dos projetos financiados por empresas ficam sob GPL, muitas instituições, tanto privadas como públicas, preferiram desenvolver licenças próprias, afastando-se, por vezes, dos critérios de “liberdades” da FSF. Com freqüência, licenças específicas foram criadas para um projeto único; contam-se centenas delas cujas diferenças são a utilização com um software proprietário, o acesso às modificações, a publicidade, os direitos particulares do dono do projeto. A seguir, uma tabela de comparação de algumas famosas licenças, segundo os critérios descritos acima\footnote{Tabela copiada do livro coletivo, \emph{Tribune Libre: Ténors de l’Informatrique Libre}, editora O’Reilly, p.200.}:

\begin{figure}[htb]
\begin{center}
\caption{Comparação de algumas das principais licenças "livres".} \label{fig1.3}
\\
\begin{tabular}{|p{4cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
Licença & Utilização com software comercial & Acesso para todos às modificações & Publicável sob certas condições & Presença de direitos particulares reservados ao dono da licença \\
\hline
GPL (\emph{General Public License}) & Não & Sim & Não & Não \\
\hline
LGPL (\emph{Lesser General Public License}) & Sim & Sim & Não & Não \\
\hline
BSD (\emph{Berkeley Software Distribution}) & Sim & Não & Não & Não \\
\hline
NPL (\emph{Netscape Public License}) & Sim & Não & Não & Sim \\
\hline
Domínio Público & Sim & Não & Sim & Não \\
\hline

\end{tabular}
\end{center}
\end{figure}


De posse dessa informação, sabemos que certas licenças criadas para proteger um projeto específico são reutilizadas para projetos independentes. De fato, alguns projetos de código aberto têm exito e chegam a ter uma influência própria dentro do mundo do “livre”. Assim, o projeto Apache, com mais de 50 \% do mercado de servidor web, criou uma licença própria (\emph{Apache Public License}), que foi copiada por muitos outros projetos. Essa licença é compatível com a GPL desde sua versão 2.0 (janeiro 2004) e é usada notavelmente por Google para alguns projetos abertos. A fundação Mozilla, dona do navegador Firefox, propõe uma licença incompatível com a GPL (\emph{Mozilla Public License}) e apesar disso recuperada pela SUN (\emph{SUN Public License}).

Isso pode representar uma concorrência para o mundo do desenvolvimento de software e sua dinâmica. A idéia da GPL foi de permitir a um conjunto de códigos em ser compiláveis, juntáveis, integráveis, assimiláveis. Por um lado, o fato de o código ser protegido pela GPL faz que ele só seja reproduzido/modificado sob o mesmo regulamento. Por isso, alguns chamaram a GPL de Vírus (GPV – \emph{General Public Virus})\footnote{Expressão pejorativa comum dentro das primeiras criticas feitas à (L)GPL.} criando e espalhando um único monopólio. Por outro, com o espalhamento de licenças livre distintas, somos confrontados a novos problemas jurídicos, vejamos:

\begin{quote}
Qual estatuto deve adotar um software contendo códigos de licenças diferentes – por exemplo, um programa que integra ao mesmo tempo código MacOS da Apple, X Server e Mozilla para dar uma versão livre de Netscape Communicator? se Além disso, a camada usuário desse novo programa fictício usa uma biblioteca Qt da Troll Tech, uma terceira licença entraria no jogo. As três provocariam limitações diferentes.\footnote{“Quel statut doit adopter un logiciel contenant du code ouvert par différentes licences – par exemple, un programme qui intègre à la fois du code MacOS d'Apple, X server et Mozilla pour donner une version libre de Netscape Navigator ? Si de plus, la couche utilisateur de ce nouveau programme fictif utilise la bibliothèque Qt de Troll Tech, une troisième licence entre en scène. Les trois licences entrainent des limitations différentes.”}
\begin{flushright}
MÜLLER, 2001, p.16.
\end{flushright}
\end{quote}

Podemos dizer que, a área de desenvolvimento de software acha-se desacelerada pela definição de estratégias jurídicas e indústrias caras e freqüentemente laboriosas. Além das diferenças sobre os efeitos externos jurídicos do modelo aberto/livre, encontramos um processo igualmente confuso na escada institucional dessas definições jurídicas. De fato, há uma concorrência no que se respeita às classificações das licenças, como meio de concorrência de legitimidade para poder definir o que é “livre/aberto” e o que não é. A FSF mantém um repertorio atualizado\footnote{http://www.gnu.org/licenses/license-list.html\#SoftwareLicenses} de todas as licenças que se apresentam como livre e as classificam em função de suas compatibilidades com as diferentes versões da GPL, ou seja, sua própria definição do livre. A \emph{Open Source Initiative}, fundada por Eric Raymond em 1998, então apoiada pela empresa Netscape, mantém um banco de dados próprio de licenças\footnote{http://www.opensource.org/licenses}, cada uma sendo submetida a um processo de aprovação respondendo a uma “definição do Open-Source”, sublinhando abertura e modelo de negócio. Da mesma maneira, a ONU, pelo intermediário de seus programas de desenvolvimento (UNDP – \emph{United Nations Developement Programs}), fundou uma instituição com o propósito de definir e desenvolver o software livre e de código aberto. 

Assim, o \emph{International Open-Source Network} (IOSN)\footnote{http://www.iosn.net. Para os desenvolvimentos a respeitos de licenciamento de projetos livre, ver: http://www.iosn.net/licensing/foss-licensing-primer/}, que age particularmente na região asia-pacífica, também define e classifica os projetos livres e suas licenças em benefício de uma concepção híbrida (Liberdade/modelo de negocio), voltado às problemáticas de inclusão/exclusão digital e de governo eletrônico. Os governos nacionais, particularmente os da França, do Brasil, da China e de Israel, focam-se mais sobre os casos de adoção pela administração de sistema open-source, favorecendo critérios de gratuidade (redução de custo) e de acesso ao código fonte (controle/segurança). Na Europa, é o caso da \emph{Interoperable Delivery of European eGovernment Services} (IDABC) e do \emph{Open Source Observatory and Repository} (OSOR). No Brasil, iniciativas semelhantes eram quase inexistentes antes de 2000 e ficavam somente em nível local, como é o caso dos telecentros que privilegiaram pouco a pouco o uso do Linux. O software Livre tornou-se prioridade no nível federal após um decreto presidencial de 2003\footnote{Decreto presidencial do dia 29 de dezembro de 2003} fornecendo ao CEGE (Comitê Executivo do Governo Eletrônico\footnote{O Comitê Executivo do Governo Eletrônico (CEGE) foi criado em 18 de outubro de 2000 no âmbito do Conselho de Governo da Presidência da República, com o objetivo de "formular políticas, estabelecer diretrizes, coordenar e articular as ações de implantação do Governo Eletrônico".}) a “implantação do software livre”. Sendo assim, o software livre é considerado como recurso estratégico, uma opção tecnológica favorecendo, a curto e longo prazo, uma autonomia e uma apropriação independente das ferramentas tecnológicas, usadas de maneira transversal em todas as realizações técnicas do governo eletrônico. Segundo Vianna (VIANNA, 2006), o software livre é um meio que garante concretamente o direito econômico ao desenvolvimento tecnológico. Esse direito traz a idéia de uma autonomia cientifica nacional como a de democratização do acesso as novas tecnologias. Seria, de acordo com as palavras do autor, uma arma “contra a colonização tecnológica dos Estados-Unidos” e um meio de garantir uma formação mais independente das elites. 

\subsection{Postulado de definição} \label{1.3.4}

Vejamos, então, que comunidades, instituições e licenças se opõem ao definir os propósitos e meios do chamado 'movimento do software livre' e assim criam uma concorrência para conquistar a legitimidade em definir o movimento. Para o sociólogo, trata-se de conseguir capturar uma forma sistemática de um objeto cuja natureza é fluida e evolutiva, como é freqüentemente o caso a respeito dos movimentos sociais, por exemplo, nas analises do movimento alter-globalização (KAVADA, 2003).

No nosso caso, as analises de rede propostas por Arturo Escobar (ESCOBAR, 2003) parecem fazer sentido com a estrutura de baixo para cima (\emph{bottom-up system}) e o alto grau de auto-gestão que se encontra nos arredores do Software Livre e de suas comunidades. Considerando a metáfora da "malha" (\emph{meshwork}) em vez da de "rede" (\emph{network}), o autor permite a observação de uma grande heterogeneidade dentro de um mesmo movimento social.

Desse jeito, podemos incluir todas as contradições sublinhadas pelos diferentes atuantes do movimento. Levando três exemplos emblemáticos, os das comunidades BSD, GNU, Mozilla, observamos que a primeira -BSD- não é ligada a uma instituição, mas a uma licença e permite usos comerciais que fechem o código. Por isso ela esta excluída da visão do "livre" da comunidade GNU, a qual esta ligada a uma instituição (FSF) e uma licença (GPL). Os softwares GNU são reconhecidos como "livres" pelas duas outras comunidades comentadas aqui. Por sua vez, a terceira comunidade -Mozilla- é também excluída pelos critérios da FSF, embora não permite o encerramento do código de seus produtos. Do ponto de vista de GNU, só GNU é "livre". Do ponto de vista de BSD, todas três são "livres". Do ponto de vista de Mozilla, só Mozilla e GNU são "livres". Ademais, a respeito da apelação "\emph{open-source}": GNU não quer se considerar Open-Source, enquanto BSD como Mozilla, consideram as três comunidades como Open-source.

Neste âmbito de oposições, postular que o movimento do livre é composto de todos os atores que pretendem fazer parte do mundo do "livre" ou "\emph{open-source}" parece um meio eficiente para capturar o movimento com toda sua complexidade, sendo possível de revelar as nuances identitárias dos atuantes ao observar um contexto determinado.

\section{O sucesso do código aberto e seus desafios contemporâneos} \label{1.4}

A mudança que aconteceu em 1998 com a cisma entre os mundos do "livre" e do "open source" tem como maior conseqüência a entrada das empresas e a atribuição de orçamentos, até então inesperados. Tais atitudes são importantes meios que são estabelecidos por empresas como IBM ou SUN para adaptarem os softwares as suas necessidades. É nessa época que vão se formar umas das vitorias decisivas do "livre" para sua fama. Por exemplo, em 1998, a IBM entra no projeto Apache, um servidor Web, mostrando uma estabilidade notável em seu desenvolvimento, enquanto os equivalentes proprietários se perdiam em reorientações constantes. Hoje, o Apache é umas das conquistas significativas do mundo do software livre, hospedando a maioria dos servidores Web do mundo (70\%)\footnote{Fonte: http://www.securityspace.com/s\_survey/data/200905/index.html}. A IBM investiu nessa época um milhão de dólares no Linux para colocá-lo nos servidores dele. O sistema operacional FreeBSD aproveitou dos investimentos de Apple e Google. Outros projetos conhecem um sucesso notável: DNS e BIND, SendMail, Samba, Perl, Python, Tcl/Tk.

Podemos observar que as aplicações livres que ganharam sucesso são relativamente "fundamentais", ou seja, sistemas e programas para servidores, protocolos de redes ou de arquivos, linguagens de programação. Neste limbo, o mundo do Desktop, do computador de escritório, do usuário final (\emph{end-user}), está para ser conquistado. Basicamente, uma máquina desktop é composta por um sistema operacional no qual são adicionados alguns elementos essenciais. Com 90\% do marketshare\footnote{Fonte: http://marketshare.hitslink.com/report.aspx?qprid=8}, a Microsoft tem quase o monopólio do sistema operacional utilizados pelos computadores pessoais (\emph{Microsoft Windows}) e reduz o uso do Linux a uma parte mínima de usuários avançados (0,90\%).  Todavia, desde 2005, Mark Shuttleworth, financia, através da sociedade de serviço \emph{Canonical Ltd.} (Reino-Unido), uma versão de Linux (Ubuntu) com objetivo de ser intuitiva e dedicada aos usuários comuns. Essa distribuição do Linux parece conseguir seu caminho no mundo do desktop, notavelmente com a sua adoção por grandes instituições (Wikimedia, Amazon.com, Policia Militar Francesa). O OpenOffice.org (OOo), alternativa ao Microsoft Office, é um projeto já antigo que se beneficia do apoio da SUN e acha-se por padrão em quase todas as distribuições do Linux, e fica também disponível para os usuários de Windows e Apple. Uma das maiores conquistas do "livre" no mundo do desktop é o browser Mozilla Firefox (22\%\footnote{Fonte: http://marketshare.hitslink.com/report.aspx?qprid=0} do mercado), que realmente consegue concorrer com o seu equivalente proprietário (Internet Explorer - 66\%), oferecendo mais segurança e adaptabilidade.

Numa observação mais geral e econômica do fenômeno do código aberto, enxerga-se a necessidade de achar modelos de financiamentos locais que permitem uma retribuição dos desenvolvedores e voluntários. O começo do projeto GNU descrevia a participação como um hobbie que podia ser retribuído com empregos ligados à área de participação voluntaria. Assim os desenvolvedores do sistema GNU/Linux usavam parte de seu tempo de trabalho como analista de sistemas, administrador de rede ou programador, para desenvolver projetos que iam dar um retorno para a empresa empregadora. Junto com o espalhamento da cultura \emph{open-source} a outras áreas, o equilibro entre voluntarismo e retribuição não estava tão bem definido. Por exemplo, projetos como a Wikipédia que faz parte dos 10 sites web os mais visitados\footnote{Fonte: http://www.alexa.com/topsites} no mundo e emprega somente 23 funcionários\footnote{Fonte: http://en.wikipedia.org/wiki/Wikimedia\_Foundation}. Nesse sentido, o movimento do software livre contribua bastante ao fenômeno de "trabalho do consumidor" (DUJARIER, 2008) fazendo o usuário-desenvolvedor criar um valor para o acionista sem custo. Num estudo sobre a nova “economia colaborativa” (\emph{Wikinomics}), o grupo de estudo New Paradigm relevou que a peça chave desse novo xadrez é a etapa de contato entre o desenvolvedor e o projeto no qual ele vai participar. Assim plataformas oferecendo ou obrigando empresas a oferecer retribuições garantem um modelo econômico transparente enquanto projetos mais informais não podem garantir um retorno para o usuário-desenvolvedor (TAPSCOTT e WILLIAMS, 2006).

A abertura das comunidades FOSS aos investimentos privados foi feita como benefício de uma visão pragmática do movimento, ou seja, apontando suas qualidades como modelo de negócio. As empresas privadas têm entendido rapidamente o interesse em favorecer a curiosidade criativa dos usuários, assim como os esforços técnicos dos desenvolvedores para adaptar os produtos às necessidades locais. Com isso, somos então afastados do conceito de \emph{copyleft} e da filosofia do projeto GNU e os exemplos que seguem vêm ilustrar os recentes avanços da parte pragmática do movimento do software livre e os problemas que podem causar. 

\subsection{O \emph{Software Development Kit} (SDK – Kit de desenvolvimento de Software)} \label{1.4.1}

O \emph{Software Development Kit} é uma plataforma de trabalho oferecida pelo produtor de uma tecnologia para que os desenvolvedores possam criar/modificar aplicativos. Trata-se de um modelo cada vez mais usado para vários tipos de produtos: hardware, OS, jogos. Esse modelo se encontra tanto para produtos livres (Qt, Java, Android), como para produtos proprietários (Flash, iPhone, Microsoft Platform) e reutiliza as principais características do modelo de desenvolvimento colaborativo, oferecendo, ou não, o acesso ao código fonte, o programa se beneficia do esforço coletivo dos usuários-desenvolvedores.

Isso poderia ser uma redução forte do conceito de \emph{open-source} ao benefício de uma visão muito rentável para a empresa. Deste modo, pode-se reduzir ao mínimo o compartilhamento de informação com a comunidade e aproveitar todas as vantagens de uma plataforma colaborativa. Particularmente, esse debate foi intenso no lançamento do Programa de Desenvolvimento para o iPhone de Apple (iPDP). O SDK era livre, tanto para abaixar como para usar, mas qualquer publicação de código necessitava de se cadastrar no programa oficial. Depois desse cadastramento, os desenvolvedores – mesmo sendo voluntários – tinham cláusula de segredo profissional. Embora o grande sucesso do dispositivo e de seu kit de desenvolvimento, as protestações foram tão fortes contra a política de Apple que a obrigação ao segredo foi levada, pelo menos, entre seus desenvolvedores (WILLIS, 2008).

Ademais, O \emph{kit} de desenvolvimento de software permite às companhias facilitar a colaboração dos usuários-desenvolvedores, continuando em limitar, como elas desejam, as compensações para a comunidade. Por isso, o SDK é uma ameaça direta ao movimento do software livre e uma restrição certa ao modelo de desenvolvimento \emph{open-source} em que seus termos, limitações e objetivos são inteiramente decididos pela sociedade emissora.

\subsection{A computação nas nuvens} \label{1.4.2}

Na área de administração de redes e de gestão das informações transmitidas, dois modelos se opõem: favorecer o cliente (descentralizar a informação) ou o servidor (centralização da informação). Os detentores de informações primeiras – engenheiros, desenvolvedores, profissionais dos TI – descrevem fenômenos cíclicos na escada da administração de redes privadas (empresas, coletividades). Mas numa escala mundial, o fenômeno parece mais constante. O desenvolvimento progressivo de aplicativos Web (Web-based) força a centralização dos dados nos servidores de algumas multinacionais. O melhor exemplo, nesse caso, são os serviços \emph{on-line} da Google. De fato, com um simples navegador, um usuário pode usar, modificar e armazenar suas fotos (Picasa, Flickr), vídeos (Youtube), blog (Wordpress, Blogger), textos, planilhas, apresentações (Zoho, Google Documents), emails (Yahoo, Gmail), itinerários (Google Maps), favoritos e rascunhos (Google Notas), contatos e agenda (Google Agenda), fluxos de informações (Google Reader), criação e hospedagem de sites (Google Page Creator), entre outros. Esse conjunto de aplicativos já excede tudo o que pode precisar um usuário de computador pessoal comum conectado à Internet. Essa situação permite afirmar que o navegador poderia se tornar a único meio necessário para usar de todos os serviços que os computadores hoje oferecem. Nesse sentido:

\begin{quote}
Na minha opinião, eu acho que os aplicativos estão passando ao modelo Web, no qual o navegador é o principal, ou o único, software. Temos em Mozilla uma piada: ‘o sistema operacional é somente um conjunto de drivers [programas fazendo funcionar os periféricos do computador, como a carta gráfica] para fazer rodar o navegador’. Dessa maneira, Windows não é melhor do que Linux ou Apple. Ele é um pano de fundo, se esquece dele. E o aplicativo para escritório, ele é nas nuvens, na Internet.\footnote{“Je pense pour ma part que les applications sont en train de passer au modèle Web, dans lequel le navigateur devient le principal, voire l'unique, logiciel. On a, chez Mozilla, une boutade : "le système d'exploitation n'est qu'un ensemble de drivers [programmes faisant fonctionner les périphériques de l'ordinateur, comme la carte graphique] servant à faire tourner le navigateur". Dans cette approche, Windows ne vaut pas mieux que Linux ou que Mac. Il est en arrière-plan, on l'oublie. Quant à l'application bureautique, elle est "dans le nuage", sur Internet.”}
\begin{flushright}
NITOT, 2008.
\end{flushright}
\end{quote}

Essa evolução é designada pela expressão “computação nas nuvens” (\emph{Cloud Computing}). Ela pode tornar-se um fenômeno notável e estável da história da microinformática, como o demonstra a saída prevista do sistema Windows Cloud, SO baseado numa versão mínima do Windows permitindo de acessar os serviços online da Microsoft. Assim sendo, o seu futuro é mais provável ainda com a multiplicação dos \emph{thin-client} (cliente leve: PDA, GSM 3ª geração, mini-notebook) cujas capacidades materiais não podem acolher os aplicativos locais tradicionais.

Embora o sucesso que teve o \emph{kernel} Linux sobre essas plataformas portáveis, o modelo de aplicativos \emph{web-based} ameaça as conquistas já obsoletas do "livre" em termo de aplicativos locais (Gimp, Open Office) oferecendo ambientes intuitivos e acessíveis de qualquer lugar conectado, mas cujo código é fechado.

\subsection{Google} \label{1.4.3}

Os atores privados tiveram um papel determinante no desenvolvimento dos softwares de código aberto e é graças a esses investimentos que muitos deles ganharam em credibilidade. Empresas como IBM (Linux), SUN (Open Office, Virtual Box, BSD), Red Hat (Fedora), Canonical (Ubuntu) participam desse esforço em função dos interesses e de estratégias próprias, mas nenhuma contribui ao fenômeno, de maneira global, como o faz o Google desde sua criação.

Criada em 1996 como simples motor de pesquisa, o algoritmo de busca deu resultados inesperados o que permitiu a empresa crescer rapidamente e de se tornar, em apenas 10 anos, um dos atores principais das novas tecnologias. Graças a um sistema de propaganda discreto e dedicado pelo exame das informações deixadas por cada usuário, a empresa tem agora um capital financeiro e uma influência consideráveis. Segundo a \emph{Harvard Business Review} (IVEN e DAVENPORT, 2008), são milhares de experimentos diários efetuados em cima do maior banco de dados sobre como as pessoas procuram, acham e usam as informações. Além disso, eles detêm o maior número de perfis e de informações sobre os usuários da internet no mundo, o Google mesmo se apresenta como: “no Google, nossa missão é organizar toda a informação do mundo”\footnote{VARDA, Kenton, Protocol Buffers: Google’s data interchange format, Google code blog, 07/07/2008.}.

Tal influência e essa capacidade de investimento - perto 30 bilhões de renda - têm contribuindo bastante ao desenvolvimento e a criação de numerosos projetos \emph{open-source}. A própria Google libera funcionários para adiantar certos projetos e financia diretamente alguns aplicativos chaves, além de organizar uma grande rede de colaboração, na qual estudantes do mundo inteiro podem prestar candidatura para participar de projetos abertos apoiada pela empresa (\emph{Google Summer of code}). Também, alguns de seus projetos são disponibilizados em código aberto (Android, Chrome).

Para terminar, as opiniões sobre as contribuições de Google à comunidade SL/CA são radicalmente divididas e ilustram bem as oposições entre adeptos do "\emph{free}" e adeptos do "\emph{open-source}". Para os mais radicais e comprometidos a preservar as raízes éticas e ideológicas do movimento, “Google is evil”\footnote{Assunto duma mailing-list do grupo Digital Freedom global Activists (DFGA – binaryfreedom.info)} (Google é o diabo) e encerra o movimento nos meios-termos já realizados pela asa pragmática, mas sob controle de um monopólio de empresa. Para os pragmáticos do movimento, o apoio é precioso e as transgressões à GPL já são freqüentes. Porém, todos ficam preocupados em observar certas contradições, indo no sentido duma estratégia de controle e de monopólio. Do ponto de vista da empresa, parece que a participação inédita que eles dão às comunidades SL/CA é tanto chave de seu sucesso, quanto um risco em ver essa mão de obra, sobre a qual não tem controle, sumir ou mudar os termos da sua produção (FABERNOVEL, 2008 e 2009).
